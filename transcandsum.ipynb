{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c7d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import librosa\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "import json\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6244d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "OPENROUTER_API_KEY = \"sk-or-v1-ab7fdbd68c20ab2bf782087b29a5354ec96b02\"\n",
    "asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    audio, sr = librosa.load(audio_file, sr=16000)\n",
    "    if len(audio) > 480000:\n",
    "        result = asr_pipeline(audio.astype(np.float32), return_timestamps=True)\n",
    "    else:\n",
    "        result = asr_pipeline(audio.astype(np.float32))\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "557af337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_openrouter(transcript):\n",
    "    try:\n",
    "        prompt = (\n",
    "            f\"Please summarize the following meeting transcript in a detailed yet concise format.\"\n",
    "            f\"Highlight key decisions, action items, important discussions, and next steps.\\n\\n\"\n",
    "            f\"Transcript:\\n{transcript}\"\n",
    "        )\n",
    "        response = requests.post(\n",
    "            url=\"https://openrouter.ai/api/v1/chat/completions\",  # API endpoint\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",  # Pass the API key\n",
    "                \"Content-Type\": \"application/json\",  # Indicate JSON content\n",
    "                \"HTTP-Referer\": \"https://yourdomain.com\",  # Optional referer header\n",
    "                \"X-Title\": \"AI Meeting Summarizer\",  # Optional request title\n",
    "            },\n",
    "            data=json.dumps({  # Convert the request body to JSON\n",
    "                \"model\": \"deepseek/deepseek-chat:free\",  # Use the free DeepSeek Chat model\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",  # User role message (typical for Chat API)\n",
    "                        \"content\": prompt  # Include the custom prompt\n",
    "                    }\n",
    "                ],\n",
    "            })\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            summary = response.json()['choices'][0]['message']['content']\n",
    "            return textwrap.fill(summary, width=100)\n",
    "        else:\n",
    "            return f\"Failed to generate summary. API returned status: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occured during summarization: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b914149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribe_and_summarize(audio_file):\n",
    "    try:\n",
    "        transcript = transcribe_audio(audio_file)\n",
    "        summary = summarize_with_openrouter(transcript)\n",
    "        return transcript, summary\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn = transcribe_and_summarize,\n",
    "    inputs = gr.Audio(type=\"filepath\", label=\"Upload MP3 File\"),\n",
    "    outputs = [\n",
    "        gr.Textbox(label=\"Meeting Transcript\"),\n",
    "        gr.Textbox(label=\"AI Generated Summary\")\n",
    "    ],\n",
    "    title = \"AI Meeting Transcriber & Summarizer\",\n",
    "    description = \"Upload a meeting recording. This tools will transcribe and summarize it using Whisper and DeepSeek\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
